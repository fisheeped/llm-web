import streamlit as st
import json
import os
import time
import requests
from datetime import datetime
from util.share_button import load_share_button
from util.strings import getcode,get_repair_json
from util.cache_data import *
from util.md import latex
import copy
from streamlit_echarts import st_echarts
from streamlit_javascript import st_javascript

# è®¾ç½® Streamlit é¡µé¢
st.set_page_config(page_title="ğŸ’¬ Chat", layout="wide")
st.logo(image="assets/kl.png", size="large", icon_image="assets/kl.png")


st.title("ğŸ’¬ Chat")
st.caption("ğŸš€ æ¥å’Œæˆ‘å¯¹è¯å§")
system_prompt_ = ""

branch_text_prompt = ""

# ä¾§è¾¹æ æ¨¡å‹å‚æ•°

with st.sidebar:
    if "model_state" not in st.session_state:
        st.session_state.model_state = {}
    index = openai_model_list.index(st.session_state.model_state.get("model_version",openai_model_list[0]))
    model_version:str = st.selectbox("model",openai_model_list, index=index) # type: ignore
    model_name = api_model_card.get(model_version).get("model_name")
    system_prompt_ = api_model_card.get(model_version).get("system_prompt")

    with st.expander("model api"):
        custom_model = st.text_input("api_model", st.session_state.model_state.get("custom_model", "") ,help="è¦†ç›–ä¸Šé¢çš„Model")
        openai_key = st.text_input("api_key",st.session_state.model_state.get("openai_key", ""),help="è¦†ç›–è‡ªå®šä¹‰çš„api_key")
        openai_url = st.text_input("api_url",st.session_state.model_state.get("openai_url", ""),help="è¦†ç›–è‡ªå®šä¹‰çš„api_url")
    with st.expander("model args"):
        temperature = st.number_input("temperature",min_value=0.0,max_value=2.0,value=st.session_state.model_state.get("temperature", 0.1),step=0.01)
        thinking = st.checkbox('thinking', value= st.session_state.model_state.get("thinking", False))
        stream = st.checkbox('stream', value=st.session_state.model_state.get("stream", True))
        # system_prompt_ = st.text_input('system_prompt',st.session_state.model_state.get("system_prompt", ""), help = "è®¾ç½®åéœ€è¦æ¸…ç©ºå†å²è®°å½•")
        if "model_state" in st.session_state:
            if len(st.session_state.model_state.get("text_prompt","").strip()) > 1:
                branch_text_prompt = st.session_state.model_state["text_prompt"]
        text_prompt = st.text_area('text_prompt',branch_text_prompt, help = "è®¾ç½®åéœ€è¦æ¸…ç©ºå†å²è®°å½•")
    
    st.session_state.model_state["model_version"] = model_version
    st.session_state.model_state["openai_key"] = openai_key
    st.session_state.model_state["openai_url"] = openai_url
    st.session_state.model_state["custom_model"] = custom_model
    st.session_state.model_state["temperature"] = temperature
    st.session_state.model_state["thinking"] = thinking
    st.session_state.model_state["stream"] = stream
    # st.session_state.model_state["system_prompt"] = system_prompt_
    st.session_state.model_state["text_prompt"] = text_prompt


    with st.expander("output args"):
        json_output = st.checkbox('json_output', value=st.session_state.model_state.get("json_output", False))
        st.session_state.model_state["json_output"] = json_output
    slide_col0,slide_col1 = st.columns(2)
    with slide_col0:
        if st.button('clear'):
            st.session_state.messages = []
            st.rerun()
    
    share_url = ""
    with slide_col1:
        if st.button("share",key="share"):
            cache_id = save_to_cache()
            current_url = st_javascript("window.location.href")
            share_url = f"{current_url}?c={cache_id}"
    if len(share_url) > 0:
        st.code(share_url)
if len(openai_key) == 0:
    openai_key = api_model_card.get(model_version).get("openai_key")
if len(openai_url) == 0:
    openai_url = api_model_card.get(model_version).get("api_url")
if len(custom_model) > 0:
    model_version = custom_model

post_url = f"{openai_url}/chat/completions"
# åˆå§‹åŒ–ä¼šè¯æ¶ˆæ¯
if "messages" not in st.session_state:
    if len(system_prompt_) > 2:
        st.session_state["messages"] = [{"role":"system", "content": system_prompt_}]
    else:
        st.session_state["messages"] = []


# å­˜å‚¨å“åº”å†…å®¹
if 'content' not in st.session_state:
    st.session_state.content = ""

if 'reasoning_content' not in st.session_state:
    st.session_state.reasoning_content = ""

# åˆå§‹åŒ–æŠ˜å æ¡†çš„æ‰“å¼€çŠ¶æ€
if 'expander_opened' not in st.session_state:
    st.session_state.expander_opened = True



def messages_filter(messages):
    """åªä¿ç•™è¿™ä¸‰ä¸ªè§’è‰²"system","user","assistant" """
    msgs = []
    for i in messages:
        if i.get("role") in ["system","user","assistant"]:
            msgs.append(i)
    return msgs



for i, msg in enumerate(st.session_state.messages):
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            options = None
            if msg["role"] == "think":
                with st.expander(f"ğŸ§", expanded=st.session_state.expander_opened):
                    st.write(msg["content"])
            else:
                if msg["role"] == "assistant":
                    if not json_output:
                        echart_data = getcode(msg["content"], mode="echarts")
                        if echart_data is not None:
                            options = get_repair_json(echart_data)
                    else:
                        echart_data = getcode(msg["content"])
                        if echart_data is not None:
                            options = get_repair_json(echart_data)
                if options and not json_output:
                    fe = msg["content"].split(echart_data)
                    st.write(latex(fe[0].split("```")[0]))
                    st_echarts(options, height="500px", key=f"echarts_{i}")
                    st.write(latex(fe[1].split("```")[-1]))
                elif options and json_output:
                    fe = msg["content"].split(echart_data)
                    st.write(latex(fe[0].split("```")[0]))
                    st.json(options)
                    st.write(latex(fe[1].split("```")[-1]))
                else:
                    st.write(latex(msg["content"]))
            elapsed_time = msg.get("elapsed_time","")
            with st.expander(f"editor\t\t\t\t{elapsed_time}"):
                new_content = st.text_area(label=f"msg-{i}",key = f"msg-{i}", value=msg["content"])
                col_0, col_1 = st.columns(2)
                with col_0:
                    edit_button = st.button("Edit", key=f"edit_{i}")
                    if edit_button:
                        st.session_state.messages[i]['content'] = new_content
                        st.rerun()
                with col_1:
                    delete_button = st.button("Delete", key=f"delete_{i}")
                    if delete_button:
                        del st.session_state.messages[i]
                        st.rerun()



# å¤„ç†æµå¼è¾“å‡º
def stream_chat():
    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
    model_ = model_name.rsplit("-test", 1)[0]
    messages_ = [{"role":"system", "content": system_prompt_}]
    messages_.extend(copy.deepcopy(st.session_state.messages))
    data = {
        "model": model_,
        "messages": messages_,
        "temperature": temperature,
        "stream": stream
    }
    if len(text_prompt.strip()) > 1:
        data["messages"][-1]["content"]= text_prompt.replace("{{ query }}",data["messages"][-1]["content"])
    if not thinking and model_.startswith("Qwen3"):
        if not data["messages"][-1]["content"].rstrip().endswith("/no_think"):
            query_ = data["messages"][-1]["content"]
            data["messages"][-1]["content"] = f"{query_} /no_think"
        # data["chat_template"] = qwen3_no_thinking_template
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {openai_key}",
    }
    st.session_state.content = ""
    st.session_state.reasoning_content = ""
    reasoning_placeholder = st.empty()
    content_placeholder = st.empty()
    expander_opened_control = True  # ç»“è®ºç”Ÿæˆæ—¶åªå…³é—­ä¸€æ¬¡
    # ç”Ÿæˆæ ¼å¼åŒ–æ—¶é—´
    formatted_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # å‘é€è¯·æ±‚
    response = requests.post(post_url, headers=headers, json=data, stream=stream)
    for line in response.iter_lines():
        decoded_line = line.decode("utf-8").strip()
        if len(line) < 1: continue
        if not decoded_line.startswith("data: {"): break
        try:
            data = json.loads(decoded_line[6:])
            delta = data["choices"][0]["delta"]
            if "content" in delta:
                st.session_state.content += delta["content"]
            elif "reasoning_content" in delta:
                st.session_state.reasoning_content += delta["reasoning_content"]
            elapsed_time = time.time() - start_time
            # è®¡ç®—æ—¶é—´å¼€é”€
            time_display = f"(Time taken: {elapsed_time:.2f} seconds)"
            if len(st.session_state.content) > 1:
                # æ€è€ƒç»“æŸï¼Œå…³é—­expanderå¹¶æ›´æ–°ç»“è®ºå†…å®¹
                if expander_opened_control:
                    expander_opened_control = False
                    with reasoning_placeholder.expander(f"ğŸ§ COT", expanded=False):
                        st.write(st.session_state.reasoning_content)
                content_placeholder.success(f"âœ… Result {formatted_time}\n{st.session_state.content}\n{time_display}")
            else:
                # æ›´æ–°å¯æŠ˜å çš„æ€è€ƒå†…å®¹
                with reasoning_placeholder.expander(f"ğŸ§ COT {formatted_time}", expanded=True):
                    st.write(st.session_state.reasoning_content)
            
        except Exception as e:
            print(e, line)
    elapsed_time = time.time() - start_time
    total_time_display = f"(Time taken: {elapsed_time:.2f} seconds)"
    # å¦‚æœæ€è€ƒå†…å®¹æœ‰æ›´æ–°ï¼ŒåŠ å…¥åˆ°æ¶ˆæ¯ä¸­
    if len(st.session_state.reasoning_content.strip()) > 2:
        st.session_state.messages.append({"role": "think", "content": st.session_state.reasoning_content})
    
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.messages.append({"role": "assistant", "content": st.session_state.content, "elapsed_time": total_time_display})


# å‘é€ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    if stream:
        stream_chat()
    else:
        text = "éæµå¼æ¨¡å¼æš‚æœªå®ç°"

    # æ¸²æŸ“ ECharts å›¾è¡¨
    st.rerun()







# å¤„ç†åˆ†äº«é“¾æ¥ä¸­çš„ç¼“å­˜æ–‡ä»¶å‚æ•°
if 'c' in st.query_params:
    cache_id = st.query_params['c']
    load_from_cache(cache_id)
    st.query_params.pop('c')
    st.rerun()
# æ¸…é™¤ç¼“å­˜æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
def clear_cache_files():
    for file in os.listdir(".cache"):
        if file.startswith("cache_") and file.endswith(".json"):
            os.remove(file)
